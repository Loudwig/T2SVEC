{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa2e114",
   "metadata": {},
   "source": [
    "# TS2Vec sur ECG5000 — Evaluation\n",
    "- Rechargement d'un run existant (EXP_ID choisi à la main)\n",
    "- Extraction des représentations + logistic regression\n",
    "- Affichage accuracies + quelques plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import models as m\n",
    "\n",
    "from sktime.datasets import load_from_tsfile_to_dataframe\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c8f84b",
   "metadata": {},
   "source": [
    "## Paths + run à recharger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR = Path.cwd()\n",
    "CURR_DIR_PARENT = list(CURR_DIR.parents)\n",
    "SRC_DIR = CURR_DIR_PARENT[0]\n",
    "\n",
    "DATA_DIR = SRC_DIR/ \"data\"\n",
    "DATASET_DIR = DATA_DIR / \"ECG5000\"\n",
    "train_path = DATASET_DIR / \"ECG5000_TRAIN.ts\"\n",
    "test_path  = DATASET_DIR / \"ECG5000_TEST.ts\"\n",
    "\n",
    "RUNS_DIR = CURR_DIR/\"runs\"\n",
    "\n",
    "EXP_NAME = \"ts2vec_ecg5000\"\n",
    "\n",
    "EXP_ID = \"0\"  \n",
    "\n",
    "EXP_DIR = RUNS_DIR / EXP_NAME / EXP_ID\n",
    "print(\"EXP_DIR:\", EXP_DIR)\n",
    "\n",
    "config_path = EXP_DIR / \"config.json\"\n",
    "state_dict_path = EXP_DIR / \"encoder.pt\"\n",
    "\n",
    "assert config_path.exists(), f\"{config_path} not found\"\n",
    "assert state_dict_path.exists(), f\"{state_dict_path} not found\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"Config load:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d3aad",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe7bd0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_from_tsfile_to_dataframe(str(train_path))\n",
    "X_test,  y_test  = load_from_tsfile_to_dataframe(str(test_path))\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape :\", X_test.shape)\n",
    "print(\"Example series shape:\", X_train.iloc[0, 0].shape)\n",
    "\n",
    "def df_to_numpy(X):\n",
    "    arr = np.stack([X.iloc[i, 0] for i in range(len(X))], axis=0)\n",
    "    return arr[..., np.newaxis]  # (N, T, 1)\n",
    "\n",
    "X_train_np = df_to_numpy(X_train)\n",
    "X_test_np  = df_to_numpy(X_test)\n",
    "\n",
    "X_train_torch = torch.from_numpy(X_train_np).float()\n",
    "X_test_torch  = torch.from_numpy(X_test_np).float()\n",
    "y_train_torch = torch.from_numpy(y_train.astype(np.int64))\n",
    "y_test_torch  = torch.from_numpy(y_test.astype(np.int64))\n",
    "\n",
    "train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset  = TensorDataset(X_test_torch,  y_test_torch)\n",
    "\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_eval_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22a24d",
   "metadata": {},
   "source": [
    "## Modèle laoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc21db",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = m.Encoder(\n",
    "    in_channel=config[\"in_channel\"],\n",
    "    representation_dim=config[\"representation_dim\"],\n",
    "    num_blocks=config[\"num_blocks\"],\n",
    "    kernel_size=config[\"kernel_size\"],\n",
    ")\n",
    "model.load_state_dict(torch.load(state_dict_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {total/1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_path = EXP_DIR / \"train_loss.npy\"\n",
    "if loss_path.exists():\n",
    "    log_np = np.load(loss_path)\n",
    "    plt.figure()\n",
    "    plt.plot(log_np)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Training loss (reloaded)\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"HierLoss\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No train_loss.npy found at\", loss_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8529b9",
   "metadata": {},
   "source": [
    "## Extraction des représentations + logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_representations(dataloader, model, device):\n",
    "    zs = []\n",
    "    ys = []\n",
    "    for x, y in dataloader:\n",
    "        # x: (B, T, 1) -> (B, 1, T)\n",
    "        x = x.to(device).permute(0, 2, 1)\n",
    "\n",
    "        r = model(x)  # (B, K, T)\n",
    "\n",
    "        \n",
    "        z = r.max(dim=-1).values # max pooling\n",
    "      \n",
    "        zs.append(z.cpu())\n",
    "        ys.append(y.cpu())\n",
    "\n",
    "    Z = torch.cat(zs, dim=0).numpy()   # (N, K)\n",
    "    y = torch.cat(ys, dim=0).numpy()   # (N,)\n",
    "    return Z, y\n",
    "\n",
    "Z_train, y_train_np = extract_representations(train_eval_loader, model, device)\n",
    "Z_test,  y_test_np  = extract_representations(test_eval_loader,  model, device)\n",
    "\n",
    "print(\"Z_train / Z_test shapes:\", Z_train.shape, Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class=\"auto\"\n",
    ")\n",
    "clf.fit(Z_train, y_train_np)\n",
    "\n",
    "y_pred_train = clf.predict(Z_train)\n",
    "y_pred_test  = clf.predict(Z_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train_np, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_np,  y_pred_test)\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.4f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1b088",
   "metadata": {},
   "source": [
    "## Visualisation rapide des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885fc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative = iter(train_eval_loader)\n",
    "x_batch, _ = next(iterative)\n",
    "x_batch = x_batch.to(device)\n",
    "out = model(x_batch.permute(0, 2, 1))\n",
    "B, _, _ = out.shape\n",
    "print(\"out shape:\", out.shape)\n",
    "print(\"x_batch shape:\", x_batch.shape)\n",
    "\n",
    "for j in range(min(B, 4)):\n",
    "    plt.figure()\n",
    "    plt.imshow(out[j].squeeze().cpu().detach(), aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Feature map sample {j}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x_batch[j].view(-1).cpu().detach())\n",
    "    plt.title(f\"Raw signal sample {j}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
